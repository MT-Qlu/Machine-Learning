{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37f96485",
   "metadata": {},
   "source": [
    "# TensorFlow Variational Autoencoder Lab\n",
    "\n",
    "### Why this notebook\n",
    "- Walk through training and sampling with the Keras VAE implementation from `../src`.\n",
    "- Provide a framework-specific companion to the PyTorch VAE for comparison and study.\n",
    "- Capture code patterns you can reuse when building generative models.\n",
    "\n",
    "### Learning objectives\n",
    "- Train the VAE with KL annealing support controlled by `CONFIG`.\n",
    "- Inspect the metrics dictionary to balance reconstruction loss and KL divergence.\n",
    "- Reconstruct inputs and generate novel samples using the decoder.\n",
    "\n",
    "### Prerequisites\n",
    "- TensorFlow 2.x installed (GPU optional but helpful).\n",
    "- Understanding of Gaussian latent variables and the reparameterisation trick.\n",
    "- Familiarity with the vanilla TensorFlow autoencoder notebook.\n",
    "\n",
    "### Notebook workflow\n",
    "1. Import config, training, and inference utilities from `tensorflow/src`.\n",
    "2. Run `train(CONFIG)` to fit the VAE and capture metrics.\n",
    "3. Load the trained model, reconstruct samples, and call `sample` for new images.\n",
    "4. Extend with latent traversals, KL schedules, or evaluation metrics (FID, log-likelihood estimates).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6e9ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_ROOT = Path(__file__).resolve().parents[2]\n",
    "SRC_ROOT = PROJECT_ROOT / 'tensorflow' / 'src'\n",
    "if str(SRC_ROOT) not in sys.path:\n",
    "    sys.path.append(str(SRC_ROOT))\n",
    "\n",
    "from config import CONFIG\n",
    "from train import train\n",
    "from inference import reconstruct, load_model, sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013de3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = train(CONFIG)\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead7fe50",
   "metadata": {},
   "source": [
    "### Interpret the metrics\n",
    "- Monitor reconstruction loss and KL divergence captured per epoch.\n",
    "- If KL drops near zero, increase `CONFIG.kl_weight` or enable annealing to prevent posterior collapse.\n",
    "- Plot both curves to understand when reconstruction dominates vs when the latent prior tightens.\n",
    "- Compare with PyTorch metrics to ensure consistent behaviour across frameworks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4e0eea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "model = load_model(CONFIG)\n",
    "dummy = np.random.uniform(-1.0, 1.0, size=(8, 28, 28, 1)).astype('float32')\n",
    "outputs = reconstruct(dummy, model=model, config=CONFIG)\n",
    "generated = sample(4, model=model, config=CONFIG)\n",
    "len(outputs), generated.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1214f74",
   "metadata": {},
   "source": [
    "### Next experiments\n",
    "- Visualise latent traversals by sampling along individual latent dimensions.\n",
    "- Experiment with Î²-VAE objectives by scaling `CONFIG.kl_weight`.\n",
    "- Export the decoder as a standalone generator and integrate it into downstream tasks.\n",
    "- Evaluate FID or other generative metrics to benchmark sample quality."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
