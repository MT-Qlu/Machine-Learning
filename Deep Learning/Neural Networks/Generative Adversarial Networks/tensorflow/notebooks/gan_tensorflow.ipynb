{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d7fced",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = train(CONFIG)\n",
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad60d92d",
   "metadata": {},
   "source": [
    "### Interpret the losses\n",
    "- `d_loss` spikes can signal discriminator dominance; try reducing learning rate or adding label smoothing.\n",
    "- `g_loss` collapsing near zero may hide vanishing gradients; adjust optimiser betas or add noise.\n",
    "- Aggregate metrics with experiment metadata (e.g., mixed precision status) for later comparison.\n",
    "- Plot both losses to spot cyclic behaviour typical of GAN training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b3f684",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = generate_samples(CONFIG, num_images=16, output_path=CONFIG.artifact_dir / 'notebook_samples.png')\n",
    "samples.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f74e01",
   "metadata": {},
   "source": [
    "### Next experiments\n",
    "- Enable `tf.keras.mixed_precision` to benchmark GPU/TPU speedups.\n",
    "- Evaluate sample grids per epoch to detect early mode collapse.\n",
    "- Introduce gradient penalty or spectral normalisation for improved stability.\n",
    "- Port the pipeline to other data (e.g., EMNIST) by customising `data.py`."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
